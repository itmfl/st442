---
title: "Introduction to Data Science"
subtitle: "Tidyr and relational data"
date: "Fall 2023"
output:
  xaringan::moon_reader:
    lib_dir: libs
    #css: ["default","metropolis-fonts","animate.css"]
    css: ["xaringan-themer.css","metropolis-fonts"]
    nature:
      highlightStyle: solarized-light
      highlightLines: false
      highlightSpans: false
      countIncrementalSlides: false
    df_print: tibble
    # css: [default, metropolis, metropolis-fonts]
--- 

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.retina = 3, fig.width = 8, fig.asp = 0.6, fig.align = 'center', out.width = "120%", warning = FALSE, message = FALSE,fig.showtext=TRUE)
library(ggplot2)
options(htmltools.dir.version = FALSE, digits = 3, knitr.table.format = "html",tibble.print_min=6, tibble.width=70)
library(knitr)
hook_output = knit_hooks$get('message')
knit_hooks$set(message = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
```


```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
library(ggplot2)
library(ggthemes)
theme_set(theme_tufte())
xaringanExtra::use_tile_view()
xaringanExtra::use_scribble()
xaringanExtra::use_extra_styles(hover_code_line = TRUE)
xaringanExtra::use_tachyons()
htmltools::tagList(
  xaringanExtra::use_clipboard(
    button_text = "<i class=\"fa fa-clipboard\"></i>",
    success_text = "<i class=\"fa fa-check\" style=\"color: #90BE6D\"></i>",
  ),
  rmarkdown::html_dependency_font_awesome()
)
#style_solarized_light()
style_duo_accent(primary_color = "#035AA6", secondary_color = "#03A696",
#style_mono_accent(base_color = "#43418A",
  #title_slide_background_color = "#FFFFFF",
  #title_slide_text_color = "#006747",
  text_font_size = 10,
  code_font_size = "0.8rem",
  link_color = "#03A696",
  header_font_google = google_font("Josefin Sans"),
  #title_slide_background_size = "600px",
  #title_slide_background_position = "bottom",
  text_font_google   = google_font("Montserrat", "300", "300i"),
  code_font_family = "Fira Code",
  #header_background_auto = TRUE,
  code_font_url = "https://cdn.rawgit.com/tonsky/FiraCode/1.204/distr/fira_code.css"
)
# duo(primary_color = "#1F4257", secondary_color = "#F97B64",
#   text_font_google   = google_font("Montserrat", "300", "300i"),
#   code_font_family = "Fira Code",
#   code_font_url = "https://cdn.rawgit.com/tonsky/FiraCode/1.204/distr/fira_code.css"
# )
```



#Tidy Data
Consider the following four different representations of the same data.

```{r echo = FALSE}
library(tidyverse)
table1 <- tribble(
  ~country, ~year, ~cases, ~population,
  "Afghanistan", 1999, 745, 19987071,
  "Afghanistan", 2000, 2666, 20595360,
  "Brazil", 1999, 37737, 172006362,
  "Brazil", 2000, 80488, 174504898,
  "China", 1999, 212258, 1272915272,
  "China", 2000, 213766, 1280428583
)

table2 <- pivot_longer(data = table1, cols = c("cases", "population"), 
                       names_to = "type", values_to = "value") |> arrange(country, year)
table3 <- table1 |> unite(rate, cases, population, sep = "/")
table4a <- table1 |> select(-population) |> pivot_wider(names_from = "year", values_from = "cases")
table4b <- table1 |> select(-cases) |> pivot_wider(names_from = "year", values_from = "population")
```
.pull-left[
```{r echo = FALSE}
library(kableExtra)
knitr::kable(table1, caption = "Table 1") |> 
  kable_styling(bootstrap_options = "striped", font_size = 14)
```
]
.pull-right[
```{r echo = FALSE}
library(kableExtra)
knitr::kable(table2, caption = "Table 2") |> 
  kable_styling(bootstrap_options = "striped", font_size = 14)
```
]
---
class: clear, middle
.pull-left[
```{r echo = FALSE}
knitr::kable(table3, caption = "Table 3") |> 
  kable_styling(bootstrap_options = "striped", font_size = 14)

```
]
.pull-right[
```{r echo = FALSE}
knitr::kable(table4a, caption = "Table 4a") |> 
  kable_styling(bootstrap_options = "striped", font_size = 14)
knitr::kable(table4b, caption = "Table 4b") |> 
  kable_styling(bootstrap_options = "striped", font_size = 14)
```
]

---
class: middle

The above tables represent the same data with quite different characteristics. 

+ For example, table $4a$ provides the simplest way for finding the difference in the number of cases between $1999$ and $2000$. 

+ Table $1$ is the easiest table to add new variables such as 
$\mathrm{GDP}$. 

+ Table $3$ is not particularly suitable for data analysis, 
but is possibly useful for data collection. 

+ Table $2$ is appropriate if the columns of Table $1$, instead of being *cases* and *populations*, are e.g., 
diseases such as *diabetes*, *HIV*, *colon cancer*, ... for which there is possibly 
missing/unobserved data (that is not all diseases are surveyed for every country). 

---
#pivoting

There is often a need to transform data between two different representations 
exemplified by Table $1$ and Table $2$ in the previous slide. 

The main tool for doing so are the verbs [pivot_longer](https://tidyr.tidyverse.org/reference/pivot_longer.html) and [pivot_wider](https://tidyr.tidyverse.org/reference/pivot_wider.html) that are part of 
the [tidyr](https://tidyr.tidyverse.org/index.html) library.  

For the motivations behind **tidyr** see the article [Tidy Data](https://www.jstatsoft.org/article/view/v059i10) by Hadley Wickham. 

See also the data tyding [cheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/master/tidyr.pdf) from **Rstudio**.

--

To convert from Table $1$ to Table $2$, we do
```{r eval = FALSE}
table2 <- pivot_longer(data = table1, cols = c("cases","population"), 
                       names_to = "type", values_to = "value")
## Equivalently
## pivot_longer(table1, c("cases","population"), "type", "value")
```

--

Conversely, to convert from Table $2$ to Table $1$, we do
```{r eval = FALSE}
table1 <- pivot_wider(table2, names_from = type, values_from = count)
```


---
class: clear
As another example, consider the following two representations of table $4a$.
.pull-left[
```{r echo = FALSE}
knitr::kable(table4a, caption = "table4a") |>
  kable_styling(bootstrap_options = "striped", font_size = 14)
```
]
.pull-right[
```{r echo = FALSE}
knitr::kable(table4a |> pivot_longer(cols = c("1999","2000"), names_to = "year", values_to = "cases") |>
  arrange(country, year), caption = "table4a_new") |> kable_styling(bootstrap_options = "striped", font_size = 14)
```
]

<br>
To go from the first representation to the second representation, we do
```{r eval = FALSE}
table4a_new <- table4a |> pivot_longer(cols = c("1999","2000"), 
                                        names_to = "year", values_to = "cases")
```
and to go from the second representation to the first, we do
```{r eval = FALSE}
table4a_new |> pivot_wider(names_from = "year", values_from = "cases") 
```
---
# Missing data and pivoting.
In our previous examples we see that **pivot_longer** and **pivot_wider** behave like inverse operations of one another. This is not always the case.

Consider the following contrived dataset.
```{r echo = 3}
options(tibble.print_min=8)
stocks <- tibble(
    year = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
    quarter = c(1,2,3,4,2,3,4),
    return = c(1.88, 0.59, 0.35, NA, 0.92, 0.17, 2.66)
)
stocks

```

How many observations are missing in the above data ? 
+ The observation for the $4$th quarter of $2015$ is *explicitly* missing
+ The observation for the $1$st quarter of $2016$ is *implicitly* missing.
---
class: clear
**pivot_longer** the `stocks` dataset and then **pivot_wider** the resulting data yields
.pull-left[
```{r}
stocks_wide <- stocks |> 
  pivot_wider(names_from = "year", 
              values_from = "return")
stocks_wide
```
]
.pull-right[
```{r}
stocks_wide |> 
  pivot_longer(cols = c("2015",
                        "2016"),
               names_to = "year",
               values_to = "return")
```
]

---
#NAs: complete() and fill()
To make missing values explicit, you can use the function [complete](https://tidyr.tidyverse.org/reference/complete.html). 

+ The function takes as input a set of columns
+ It then finds all unique combinations of their values 
+ Then ensures that the original dataset contains all these combinations by filling in explicit `NA`

There are also occasions in which a missing value is not really missing; instead a missing value indicate that the previous value should be carried forward.

+ This is common when data are generated via manual data entry.
+ We can  use [fill](https://tidyr.tidyverse.org/reference/fill.html) to replace `NA` with the most recent non-`NA` value.

.pull-left[
```{r echo=-1}
options(tibble.print_min=6)
treatment <- tribble(
  ~person, ~treatment, ~response,
  "Luigi", 0, 7,
  NA, NA, 10,
  NA, 1, 9,
  "Mario", 1, 4
)
```
]
.pull-right[
```{r}
treatment |> fill(person,treatment)
```
]
---
#separate() and unite()
We recall the following two tables

.pull-left[
```{r echo = 2}
table1 <- tribble(
  ~country, ~year, ~cases, ~population,
  "Afghanistan", 1999, 745, 19987071,
  "Afghanistan", 2000, 2666, 20595360,
  "Brazil", 1999, 37737, 172006362,
  "Brazil", 2000, 80488, 174504898,
  "China", 1999, 212258, 1272915272,
  "China", 2000, 213766, 1280428583
)
table1
```
]
.pull-right[
```{r}
table3
```
]

<br>
Table $3$ is obtained by combining the columns `cases` and `populations` in Table $1$ into the column `rate` and separating the values with `/`. 

Note that the `rate` column has type $\langle\mathrm{chr}\rangle$ in contrast to the type of $\langle \mathrm{dbl} \rangle$ for `cases` and `populations`.
---
class: clear

To go from Table $3$ to Table $1$, we do either

.pull-left[
```{r}
table3 |> 
  separate(rate, 
          into=c("cases",
                 "population"), 
          sep = "/")
```
]

.pull-right[
```{r}
table3 |> 
  separate(rate, 
           into=c("cases",
                  "population"), 
           sep = "/", convert = TRUE)
```
]
---
class: clear
The inverse of [separate](https://tidyr.tidyverse.org/reference/separate.html) is [unite](https://tidyr.tidyverse.org/reference/unite.html), e.g.,
<br>
.pull-left[
```{r}
table1 |> 
  unite(rate, cases, population)
```
]

.pull-right[
```{r}
table1 |> 
  unite(rate, cases, population,
        sep = "/")
```
]
---
# Example 1: Tidying tuberculosis

For this example we use the following dataset from the $2014$ World Health Organization (WHO) Global Tubercolosis Report. This dataset records the number of cases of tubercolosis in countries around the world during the period of $1980$ through $2013$. 
```{r eval = require('DT'), tidy = FALSE}
who
```
---
class: clear
The dataset contains quite a lot of redundant columns and missing observations. 

Also, the numerous columns whose names start with `new` indicate that these columns' names should be recorded as values as opposed to being variables names.

We thus start by pivoting the data to a longer format.
```{r}
who1 <- who |> 
  select(-iso2,-iso3) |>
  pivot_longer(col = -c("country","year"), names_to = "code", 
               values_to = "cases", values_drop_na = TRUE)
who1
```
---
class: clear
```{r}
who1 |> count(code) |> select(code) |> pull()
```

--
The columns whose names begin with $\mathrm{new}$ has the following interpretation.

+ $\mathrm{new}$ denote that the column contains new cases of TB.
+ The next $2$ or $3$ letters describe the type of TB, namely
    - $\mathrm{rel}$ for relapse
    - $\mathrm{ep}$ for extrapulmonary TB
    - $\mathrm{sn}$ for pulmonary TB that are smear negative.
    - $\mathrm{sp}$ for pulmonary TB that are smear positive.
+ $\mathrm{m}$ and $\mathrm{f}$ denote gender.
+ The numbers denote the age group/age range.

---
class: middle

We note that the relapse cases are coded as `newrel` as opposed to `new_rel` like the remaining cases. 

We thus rename `newrel` to `new_rel` and then separate the `code` column into four columns according to the above scheme. 

Note that we call **separate** twice; the second separate splits at a specified location in the string.
```{r}
who2 <- who1 |> 
  mutate(key = stringr::str_replace(code, "newrel", "new_rel")) |>
  separate(code, into = c("new", "type", "sexage")) |>
  select(-new) |>
  separate(sexage, into = c("sex", "age"), sep = 1)
```
---
class: clear
```{r}
who2
```

The data is now in a tidy format. In summary, we did
```{r eval = FALSE}
who_tidy <- who |> 
  pivot_longer(cols = 5:60, names_to = "code", 
               values_to = "cases", values_drop_na = TRUE) |>
  mutate(code = stringr::str_replace(key, "newrel", "new_rel")) |>
  separate(code, into = c("new", "type", "sexage")) |> 
  select(-new, -iso2, -iso3) |>
  separate(sexage, into = c("sex", "age"), sep = 1)
```
---
#Example 2: Names and gender
As another example of the use of **pivot_longer()** and **pivot_wider()**, 
suppose we want to summarize the number of people with a given name based on gender.

```{r}
library(babynames)
babynames
```
---
class: clear
.pull-left[
```{r}
library(babynames)
babynames |> 
  filter(name == "Sue") |>
  group_by(name, sex) |> 
  summarise(total = sum(n))
```
]

.pull-right[
```{r}
library(babynames)
babynames |> 
  filter(name == "Robin") |>
  group_by(name, sex) |> 
  summarise(total = sum(n))
```
]

We see that a person named "Sue" is most likely to be female while a person name "Robin" could have reasonable chances of being either male or female.

---
class: clear

If we now take a collection of names, and look at the number of people with these names based on gender, we might get either

.pull-left[
```{r}
names <- c("Sue", "Robin", "Leslie")
babynames |> 
  filter(name %in% names) |>
  group_by(name, sex) |>
  summarise(total = sum(n))
```
]

.pull-right[

```{r}
names <- c("Sue", "Robin", "Leslie")
babynames |> 
  filter(name %in% names) |>
  group_by(name, sex) |>
  summarise(total = sum(n)) |>
  pivot_wider(names_from = "sex", 
              values_from = "total")
```
]

<br>
We see that the use of **pivot_wider()** yield a representation of the data that is more conducive to our goal of determining names that are most gender-neutral.
---
class: clear
We can now determine the most gender-neutral names for the whole babynames dataset.
```{r}
babynames_wide <- babynames |>
  group_by(sex, name) |>
  summarise(total = sum(n)) |>
  ## set missing values in wide table to 0
  pivot_wider(names_from = "sex", values_from = "total", values_fill = 0)
babynames_wide |> filter(M > 50000, F > 50000) |>
  mutate(ratio = pmin(F/M, M/F)) |> ## parallel min
  arrange(desc(ratio)) |>
  head(6)
```
---
# Mutating join()
We recall the following tables

.pull-left[
```{r echo = FALSE}
knitr::kable(table1, caption = "table1") |> kable_styling(bootstrap_options = "striped", font_size = 14)
```
]

.pull-right[
```{r echo = FALSE}
knitr::kable(table4a, capton = "table4a") |> kable_styling(bootstrap_options = "striped", font_size = 14)
```
<br>
<br>
```{r echo = FALSE}
knitr::kable(table4b, caption = "table4b") |> kable_styling(bootstrap_options = "striped", font_size = 14)
```
]
---
class: clear
To go from table $4a$ and $4b$ to Table $1$, we need to reshape them into long tables and then combine columns. More specifically
.pull-left[
```{r eval = FALSE}
table4a.long <- table4a |> 
  pivot_longer(
    cols = c("1999","2000"),
    names_to = "year", 
    values_to = "cases") |> 
  arrange(year)
```
```{r echo = FALSE}
knitr::kable(table4a  |>
             pivot_longer(cols = c("1999","2000"),
               names_to = "year", 
               values_to = "cases") |> 
  arrange(year)) |> kable_styling(bootstrap_options = "striped", font_size = 14)
```
]
.pull-right[
```{r eval = FALSE}
table4b.long <- table4b |> 
  pivot_longer(
    cols = c("1999","2000"),
    names_to = "year", 
    values_to = "cases") |> 
  arrange(year)
```
```{r echo = FALSE}

knitr::kable(table4b  |>
             pivot_longer(cols = c("1999","2000"),
               names_to = "year", 
               values_to = "cases") |> 
  arrange(year)) |> kable_styling(bootstrap_options = "striped", font_size = 14)
```
]
---
class: clear
We then **join** the columns of the **reshaped** table $4b$ to that of the **reshaped** table $4a$. The join operation we are doing is termed a [mutating join](https://dplyr.tidyverse.org/reference/mutate-joins.html).
```{r eval=FALSE}
table4a.long |> left_join(table4b.long)
```
```{r echo = FALSE, message = TRUE}
table4a.long <- table4a |> 
  pivot_longer(cols = c("1999","2000"),names_to = "year", values_to = "cases") |> 
  arrange(year)
table4b.long <- table4b |> 
  pivot_longer(cols = c("1999","2000"), names_to = "year", values_to = "cases") |> 
  arrange(year)
table.joined <- table4a.long |> left_join(table4b.long)
knitr::kable(table.joined) |>
  kable_styling(bootstrap_options = "striped", font_size = 14)
```
---
class: clear
The help page for [mutating join](https://dplyr.tidyverse.org/reference/mutate-joins.html) operations include
+ $\mathrm{left\_join}(x,y, \mathrm{by} = \mathrm{NULL}, ...)$: return all rows from $x$, and all columns from $x$ and $y$. Rows in $x$ with no match in $y$ will have $\mathrm{NA}$ values in the new columns. If there are multiple matches between $x$ and $y$ then all combination of the matches are returned.
+ $\mathrm{right\_join}(x,y,\mathrm{by} = \mathrm{NULL}, ...)$: return all rows from $y$, and all columns from $x$ and $y$. Rows in $y$ with no match in $x$ will have $\mathrm{NA}$ values in the new columns...
+ $\mathrm{inner\_join}(x,y,\mathrm{by} = \mathrm{NULL}, ...)$: return all rows from $x$ where there are matching values in $y$, and all columns from $x$ and $y$...
+ $\mathrm{full\_join}(x,y,\mathrm{by} = \mathrm{NULL}, ...)$: return all rows and all columns from both x and y. Where there are not matching values, returns $\mathrm{NA}$ for the one missing.

```{r echo = FALSE, out.width="80%"}
knitr::include_graphics("https://d33wubrfki0l68.cloudfront.net/aeab386461820b029b7e7606ccff1286f623bae1/ef0d4/diagrams/join-venn.png")
```
---
#Visualizing joins
.pull-left[
```{r echo = FALSE, out.width="50%", fig.cap = "Join setup; figure from Section 13.4 of R4DS"}
knitr::include_graphics("https://d33wubrfki0l68.cloudfront.net/108c0749d084c03103f8e1e8276c20e06357b124/5f113/diagrams/join-setup.png")
```
]
.pull-right[
```{r echo = FALSE, fig.cap="Inner join"}
knitr::include_graphics("https://d33wubrfki0l68.cloudfront.net/3abea0b730526c3f053a3838953c35a0ccbe8980/7f29b/diagrams/join-inner.png")
```
]
---
class: clear
```{r echo = FALSE, out.width="50%", fig.cap = "Outer joins"}
knitr::include_graphics("https://d33wubrfki0l68.cloudfront.net/9c12ca9e12ed26a7c5d2aa08e36d2ac4fb593f1e/79980/diagrams/join-outer.png")
```
---
class: clear
```{r echo = FALSE, out.width="50%", fig.cap = "Duplicate keys (one to many)"}
knitr::include_graphics("https://d33wubrfki0l68.cloudfront.net/6faac3e996263827cb57fc5803df6192541a9a4b/c7d74/diagrams/join-one-to-many.png")
```
```{r echo = FALSE, out.width="50%", fig.cap = "Duplicate keys (many to many)"}
knitr::include_graphics("https://d33wubrfki0l68.cloudfront.net/d37530bbf7749f48c02684013ae72b2996b07e25/37510/diagrams/join-many-to-many.png")
```

---
#Combining multiple tables
The **join()** operations are particularly important for combining multiple tables. For illustrastion we look at the following tables from the **nycflights13** library.

+ **flights**: contains information about flights departing NYC airports during $2013$.
+ **airlines**: maps abbreviated code to full carrier name.
+ **airports**: gives information about each airport as identified by its FAA code.
+ **planes**: gives information about each plane as identified by its *tailnum*
+ **weather**: provides weather information at each NYC airport for each hour.

```{r echo = -c(1,2)}
library(nycflights13)
options(tibble.print_max = 3, tibble.print_min=3)
flights
```
---
class: clear
```{r}
airlines
airports
```
---
class: clear
```{r}
planes
weather
```
---
class: clear
Suppose we now want to get the full airlines name for each flights (as opposed to the carrier code). For ease of presentation, we will only include a subset of the original columns for the **flights** data frame.
```{r echo = -1, message = TRUE}
options(tibble.print_max = 3, tibble.print_min=3)
flights.sml <- select(flights, year:day, dep_time, tailnum, carrier, dest)
flights.sml
flights.sml |> inner_join(airlines)
```
---
class: clear
Suppose that we want to get detailed information about the airplanes used in the flights.
In this case, we want to match the observations in both table using the *tailnum* column.
```{r echo = -1, message = TRUE}
options(tibble.print_max = 3, tibble.print_min=3)
flights.sml |> inner_join(planes)
flights.sml |> inner_join(planes, by = "tailnum")
```
---
class: clear
Comparing the following two variants of **join()**, we see that there are values in the *tailnum* column of the **flights** table
that do not appear in the **planes** table. 

We thus need to be careful when using **inner_join()** as it can silently remove observations.

```{r message = TRUE}
flights.sml |> left_join(planes, by = "tailnum")
flights.sml |> inner_join(planes, by = "tailnum")
```
---
class: clear
When the identifying key of one table is different from the other table, we use `by = c("a" = "b")`, e.g.,
```{r}
airports
flights.sml |> left_join(airports, by = c("dest" = "faa"))
```
---
#Filtering joins
These operations match observations in the same way as `left_join(x,y)`, but instead of adding new columns to $x$, they only filter the observations in $x$. More specifically

+ `semi_join(x,y)` keeps all observations in $x$ that have a match in $y$.
+ `anti_join(x,y)` keeps all observations in $x$ that **do not** have a match in $y$.

For example, suppose we are interested in all flights that go to the top ten most popular destinations. We first find these destinations and then filter flights to these destinations.

```{r}
top_dest <- flights |> group_by(dest) |> summarise(count = n()) |> 
  arrange(desc(count)) |> head(10)
```
---
class: clear
.pull-left[
```{r}
flights |> 
  filter(dest %in% top_dest$dest) |>
  select(year:day, dest)
```
]
.pull-right[
```{r}
flights |> semi_join(top_dest) |>
  select(year:day, dest)
```
]
---
class: clear
As another example of filtering joins, we noted that not all the tailnum associated with planes used in the **flights** table appeared in the **planes** table. 

We might want to count how many flights are associated with each of these tailnum.
```{r}
flights |> anti_join(planes, by = "tailnum") |>
  group_by(tailnum) |> summarise(n = n()) |> arrange(desc(n))
```
---
# Example 3: US Healthcare
We now present a more involved example of tidying data with **tidyr** and joining tables and wrangling data with **dplyr** verbs. 

The example uses health care data from the **Kaiser Family Foundation** and we follow the analysis of [S. Hicks and R. Peng](https://jhu-advdatasci.github.io/2018/lectures/03-tidyverse-1.html).

The data is included in three csv files
+ one file records state-level health insurance coverage from $2013$ to $2016$
+ another file records state-level health care expenditures from $1991$ to $2014$
+ the third file records state-level life expectancy at birth.

We take a look at the first few lines of the health insurance coverage csv file. 
```{r}
library(readr)
read_lines(file = "https://bit.ly/2YLGiyx", n_max = 5)
```
---
class: clear
Ignore the first two lines. The third line contains column names. Hence
```{r warning = TRUE}
## read_csv is part of the readr library.
coverage <- read_csv(file = "https://bit.ly/2YLGiyx", 
                     skip = 2, col_names = TRUE)
coverage[53:nrow(coverage),]
```
---
class: clear
The first $52$ lines appear fine. The $53$-rd line onwards appear to be notes/annotations and should be ignore.
```{r}
coverage <- coverage[1:(which(coverage$Location == "Notes") - 1),]
## Equivalently
## coverage |> filter(cumall(Location != "Notes"))
```
The structure of the remaining two files recording health spending and life expectancy are similar. Hence
```{r}
spending <- read_csv(file = "https://bit.ly/33j3fZm", 
                     skip = 2,  col_names = TRUE)
spending <- spending |> filter(cumall(Location != "Notes"))
life_exp <- read_csv(file = "https://bit.ly/2MK13Es", 
                     skip = 2, col_names = TRUE)
life_exp <- life_exp |> filter(cumall(Location != "Sources"))
```
---
class: clear
We now take a *glimpse* at the coverage data. 
```{r output.lines = 10}
glimpse(coverage)
```
---
class: clear
The data is **untidy** and needs a bit of pivoting
```{r error = TRUE}
coverage_long <- coverage |>  
  pivot_longer(cols = -c("Location"), 
               names_to  = "year_type", values_to = "tot_coverage")

```
Hmm, this is annoying. It turns out that the variables like `2013__Other Public` contains missing values which are coded as "N/A" and not `NA`. 

---
class: clear

Luckily enough, tis is but a scratch.
```{r}
coverage <- coverage |> mutate(across(contains("Public"),as.numeric))
glimpse(coverage)
```

---
class: clear
```{r}
coverage_long <- coverage |>  
  pivot_longer(cols = -c("Location"), 
               names_to  = "year_type", values_to = "tot_coverage")
coverage_long
```

The spending data is also untidy. More pivoting
```{r}
spending_long <- spending |> 
  pivot_longer(cols = -c("Location"), 
               names_to = "year", values_to = "tot_spending")
spending_long
```
---
class: clear
We now separate the `year` column for the **spending** data and the `year_type` column for the **coverage** data
```{r}
spending_long <- spending_long |> 
  separate(year, sep = "__", into = c("year", "name"), convert = TRUE) |>
  select(-name)
spending_long
coverage_long <- coverage_long |>
  separate(year_type, sep = "__", into = c("year", "type"), convert = TRUE)
coverage_long
```
---
class: clear
We also clean up the column names of the **life_exp** data frame.
```{r}
life_exp <- life_exp |> 
  rename(life_exp_years = `Life Expectancy at Birth (years)`)
```

We now add more contextual information to the **coverage** dataframe, such as the state region and abbreviation. 
These information are available from the **state** dataframe in the [datasets](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/datasets-package.html) library. 
We note that the **coverage** data frame includes records for Washington DC, which is missing from the state dataset. 
```{r}
library(datasets)
data(state)
states.df <- tibble(
  state.name = c(state.name, "District of Columbia"),
  state.abb =  c(state.abb, "DC"),
  state.region = as.factor(c(as.character(state.region), "South")))
coverage_long <- coverage_long |> 
  left_join(states.df, by = c("Location" = "state.name"))
coverage_long
```
---
class: clear

We now merge the **coverage**, **spending** and **life_exp** data frames together. The **coverage** data frame records span $2013$ to $2016$ while the **spending** data frame records span $1991$ to $2014$. In this case we wants to include only the years $2013$ and $2014$ in the merged datasets.
```{r message = TRUE}
hc <- coverage_long |> 
  inner_join(spending_long) |>
  inner_join(life_exp)
hc
```
---
class: clear
Our data is now in a reasonable format for visualization and further analysis. One problem remains in that "Total" is not a valid type of healthcare coverage. Rather, a row for which `type = "Total"` 
is a record of the total number of people in that state. We remedy this issue via
```{r messages = TRUE}
pop <- hc |> 
  filter(type == "Total") |>
  select(Location, year, tot_coverage) |>
  rename(tot_population = tot_coverage)
hc <- hc |>
  filter(Location != "United States", type != "Total") |>
  left_join(pop) |> select(Location, year, type, tot_population, everything())
hc
```
---
class: clear
Let us now try to answer the following question of "Is there a relationship between healthcare coverage and healthcare spending in the US ?" We take a look at Employer type coverage for $2013$. A naive visualization indicates a strong relationship, but there is confounding effect due to population size.

```{r out.width = "120%", fig.asp = 0.3, echo = FALSE}
library(gridExtra)
theme_set(theme_classic())
df <- hc |> filter(type == "Employer", year == "2013")
p1 <- df |> ggplot(aes(x = tot_spending, y = tot_coverage)) + 
  geom_point() + xlab("spending") + ylab("coverage")
p2 <- df |> ggplot(aes(x = tot_population, y = tot_spending)) + 
  geom_point() + xlab("population") + ylab("spending")
p3 <- df |> ggplot(aes(x = tot_population, y = tot_coverage)) + 
  geom_point() + xlab("population") + ylab("coverage")
grid.arrange(p1,p2,p3,ncol = 3)
```
---
class: clear
If we remove the effect of population, the relationship between spending and coverage becomes much weaker. 
```{r out.width = "70%"}
hc <- hc |>
  mutate(spending_capita = (tot_spending*10^6)/tot_population,
         prop_coverage = tot_coverage/tot_population)
hc |> filter(type == "Employer", year == "2013") |>
  ggplot(aes(x = spending_capita, y = prop_coverage)) +
  geom_point() + xlab("spending per capita") + 
  ylab("proportion of Employer coverage") + geom_smooth(method = "lm")
```
---
# Automation and iteration
Compare the following code chunks.
.pull-left[
```{r}
df <- tibble(
  a = rnorm(100),
  b = rnorm(100),
  c = rnorm(100),
  d = rnorm(100)
)
output <- numeric(length(df))
for(i in seq_along(df)){
  output[i] <- median(df[[i]])
}
output
apply(df,2,median)
```
]

.pull-right[
```{r}
lapply(df,median)
sapply(df,median)
```
]
---
class: clear
The **apply** family of operations allow for complex iteration over elements of a data frame, list, or matrix, without the need to write explicit loops construct. As another example, compare

.pull-left[
```{r}
probs = c(0.25,0.5,0.75)
output2 <- matrix(0, length(probs), 
                     length(df))
for(i in seq_along(df)){
  output2[,i] <- quantile(df[[i]], 
                          probs)
}
output2
```
]

.pull-right[
```{r}
apply(df, 2, quantile, probs)
sapply(df, quantile, probs)
```
]
---
class: clear

There are numerous variants of *apply*, including

+ $\mathrm{apply}(X, \mathrm{margin}, \mathrm{FUN}, ...)$ which takes a data frame, array or matrix $X$ and returns a vector/array/list of values obtained by applying $\mathrm{FUN}$ to the margins (e.g., rows and columns) of $X$. 

+ $\mathrm{lapply}(X, \mathrm{FUN}, ...)$ which takes a list $X$ and return a list of the same length as $X$, each element of which is the result of applying $\mathrm{FUN}$ to the corresponding element of $X$.

+ $\mathrm{sapply}(X, \mathrm{FUN}, ...)$ is a user-friendly wrapper of $\mathrm{lapply}$ that try to return a vector, matrix, or array, if possible.

+ $\mathrm{mapply}(\mathrm{FUN}, ..., \mathrm{MoreArgs})$ is a multivariate version of $\mathrm{sapply}$; $\mathrm{mapply}$ applies FUN to the first elements of each $...$ argument, the second elements, the third elements, and so on.

+ $\mathrm{tapply}(X, \mathrm{INDEX}, \mathrm{FUN} = \mathrm{NULL}, ...)$ apply $\mathrm{FUN}$ to each (non-empty) group of values of $X$ given by a unique combination of the levels of factors contained in the list $\mathrm{INDEX}$

---
class: clear
The following are some examples of *apply* and its variants.

```{r}
# ?beaver1 and ?beaver2
beaver <- list(beaver1 = beaver1, beaver2 = beaver2)
lapply(beaver, function(x) apply(x,2,mean))
sapply(beaver, function(x) apply(x,2,mean))
```

---
class: clear
```{r echo = -1}
options(tibble.print_max = 6, tibble.print_min=6)
head(mtcars)
tapply(mtcars$mpg, mtcars$cyl, mean) ## Work like group_by and summarise
tapply(mtcars$mpg, list(mtcars$cyl, mtcars$gear), mean)
```

---
class: clear

Nesting a *tapply* within an *apply* is particularly useful.
```{r}
apply(mtcars, 2, function(x) tapply(x, mtcars$cyl, mean))
```

We end with some examples of *mapply*

.pull-left[
```{r}
mapply(rep, 1:4, 4:1)
```
]

.pull-right[
```{r}
mapply(rep, 4:1, 1:4)
```
]
---
class: clear
```{r}
mapply(rep, 1:4, 4)
X <- cbind(1:5, 6:10)
mapply(function(x,y) x*y, X[,1], X[,2])
```
---
#Purrr: an alternative to apply()
The [apply](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/apply) family of operations are powerful, but its syntax is somewhat inconsistent. The [purrr](https://purrr.tidyverse.org/) 
library (a part of the [tidyverse](https://www.tidyverse.org/) ecosystem provides analogous operations with a cleaner syntax. 

These operations are (here $.x$ is a list or atomic vector and $.f$ is a function, **formula**, or vector.

+ $\mathrm{map}(.x, .f, ...)$: makes a list
+ $\mathrm{map\_lgl}(.x, .f, ...)$: makes a logical vector
+ $\mathrm{map\_int}(.x, .f, ...)$: makes an integer vector
+ $\mathrm{map\_dbl}(.x, .f, ...)$: makes a double vector
+ $\mathrm{map\_chr}(.x, .f, ...)$: makes a character vector
+ $\mathrm{map\_dfr}(.x, .f, ...)$ and $\mathrm{map\_dfc}(.x, .f, ...)$ makes a data-frame by row-binding or column binding.

---
class: clear

The $.f$ argument to $\mathrm{map\_*}$ can be either a **formula**, a string, or a number. 
For example (here we use the **dplyr** verb $\mathrm{group\_split}$ to split a data frame into groups based on a factor)

.pull-left[
```{r}
models <- mtcars |> 
  group_split(cyl) |> 
  map(function(df) 
    lm(mpg ~ wt, data = df))

models |> map(summary) |> 
  map_dbl(function(x) x$r.squared)
```
]

.pull-right[
```{r}
models <- mtcars |> 
  group_split(cyl) |>
  map(~ lm(mpg ~ wt, data = .))

models |> map(summary) |> 
  map_dbl(~ .$r.squared)

## Equivalently
models |> map(summary) |>
  map_dbl("r.squared")
```
]
---
class: clear
To clarify the previous slide, consider
```{r output.lines = 12}
str(models)
names(models[[1]])
```
---
class: clear
```{r output.lines = 12}
str(summary(models[[1]]))
names(summary(models[[1]]))
```
---
class: clear
```{r}
x <- list(list(1,2,3), list(4,5,6), list(7,8,9))
## Extract 2nd element from each list
x |> sapply('[[',2) 
x |> sapply('[' ,2) ## this does not work
x |> map_dbl(2)
```
---
class: clear
The analogue of `mapply` for mapping over multiple arguments is `map2` and `pmap`.
.pull-left[
```{r}
mean = c(0,1,2)
sd = c(1,2,3)
mapply(rnorm, mean, sd, 3) ## Oops
mapply(rnorm, mean = mean, 
       sd = sd, n = 3)
```
]

.pull-right[
```{r}
pmap_dfc(list(mean = mean,sd = sd), 
         rnorm, 3)
```
]

---
class: clear
For even more complex iterations, there is `invoke_map`, e.g.,
.pull-left[
```{r code-label, eval = FALSE}
f <- c("runif", "rnorm", "rbinom")
param <- list(
  list(min = -1, max = 1),
  list(sd = 5),
  list(size = 10, prob = 0.5)
)
invoke_map(f, param, n = 1)

n <- list(list(n = 2),
          list(n = 3),
          list(n = 4))

invoke_map(f, 
  map2(.x = param, .y = n, c))
```
]

.pull-right[
```{r code-label-out, ref.label = "code-label", echo = FALSE}
```
]

---
#Example 4: Baseball winning %
In this example we try to model the winning percentage of baseball teams in terms of simpler statistics such as the number of runs scored and runs allowed.
We follow the presentation from section 4.2 and 7.5 of [MDSR](https://mdsr-book.github.io/mdsre).

A popular model in [sabermetrics](https://en.wikipedia.org/wiki/Sabermetrics)
is that a rough estimate of a team's expected winning percentage is (here $RS$ and $RA$ denote the total number of runs scored and runs allowed in a season). 
$$\widehat{Wpct} = \frac{1}{1 + (RA/RS)^{k}}$$
for some choice of $k$; [Bill James](https://en.wikipedia.org/wiki/Bill_James) posited that $k = 2$. 

We now verify this expression using data from the [Lahman](https://cran.r-project.org/web/packages/Lahman/index.html) library.
---
class: clear
```{r cache = TRUE, out.width="70%", echo = -1}
options(tibble.print_max = 3, tibble.print_min=3)
exp_wpct <- function(x, k = 2) { 
  return(1/(1 + (1/x)^k))
}
library(Lahman)
TeamRuns <- Teams |> 
  rename(RS = R) |> 
  mutate(wpct = W / (W + L), run_ratio = RS/RA, 
         hat.wpct = exp_wpct(run_ratio)) |>
  select(yearID, teamID, lgID, wpct, hat.wpct, run_ratio) 
TeamRuns
```
---
class: clear
The following figure provides reasonably strong support to Bill Jame's formula.
```{r out.width="80%"}
ggplot(data = TeamRuns, aes(x = run_ratio, y = wpct)) +
  geom_vline(xintercept = 1, color = "darkgray", linetype = 2) +
  geom_hline(yintercept = 0.5, color = "darkgray", linetype = 2) +
  geom_point(alpha = 0.3) + 
  stat_function(fun = exp_wpct, size = 2, color = "blue") + 
  xlab("Ratio of Runs Scored to Runs Allowed") + ylab("Winning Percentage")
```
---
class: clear
Nevertheless, we might ask whether or not $k = 2$ really the "optimal" choice for this data ? 

To answer this, we find $\hat{k}$ minimizing the (non-linear) least square criterion
$$\min_{k} \sum_{i} \Bigl(\mathrm{Wpct}_{i} - \frac{1}{1 + (\mathrm{RA}_i/\mathrm{RS}_i)^{k}} \Bigr)^2.$$

Efficient algorithms for finding $\hat{k}$ are reasonably complicated but for our current purpose, the following grid search is sufficient. 

```{r}
kseq <- seq(from = 0.5, to = 2.5, by = 0.01)
names(kseq) <- kseq
mse <- map_dbl(kseq, 
        .f = function(x,y,k) mean((y - exp_wpct(x,k))^2),
        x = TeamRuns$run_ratio, y = TeamRuns$wpct)
glimpse(mse)
which.min(mse)
```

We see that the optimal $k$ for this data is roughly $1.87$.
---
class: clear
We might want to see how the "optimal" value of $k$ changes over time. We see that the optimal $k$ over time ranges from $1.74$ to $2.02$. 
```{r}
fit.k <- function(df, 
                  kseq = seq(from = 0.5, to = 2.5, by = 0.01), 
                  name1, name2){
  mse <- map_dbl(.x = kseq, 
          .f = function(x,y,k) mean((y - exp_wpct(x,k))^2),
          x = df[[name1]], y = df[[name2]])
  idx <- which.min(mse)
  return(tibble(k = kseq[idx]))
}
kseq <- seq(from = 0.5, to = 2.5, by = 0.01)
kstar <- TeamRuns |> mutate(decade = yearID %/%10 * 10) |>
  group_split(decade) |> map_df(fit.k, name1 = "run_ratio", name2 = "wpct")
kstar
```
---
class: clear
Continuing in the same vein, let us identify, for each season, the team that led their league in home runs. 

+ We first write a helper function that, given records for a subset of teams,  return a data frame listing the team with the most home runs. 
+ We then split our data in groups based on $\mathrm{yearID}$ and $\mathrm{lgID}$ and apply our helper function to each group.
```{r}
hr_leader <- function(x){
  x |> select(yearID, lgID, teamID, HR) |>
    arrange(desc(HR)) |> head(n = 1)
}
library(Lahman)
hr_leaders <- Teams |> group_split(yearID, lgID) |>
  map_df(hr_leader)
hr_leaders
```
---
class: clear
We then visualize how the number of home runs of the top hitting teams change over time.
```{r out.width="80%"}
hr_leaders |> 
  filter(yearID >= 1916) |>
  ggplot(aes(x = yearID, y = HR, color = lgID)) + geom_line() + 
    geom_point() + geom_smooth(se = 0) + geom_vline(xintercept = 1973) + 
    annotate("text", x = 1974, y = 25, 
             label = "AL adopts designated hitter rule", hjust = "left")
```